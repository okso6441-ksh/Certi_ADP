{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 컨텐츠 기반 필터링 실습 – TMDB 5000 Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "movies =pd.read_csv('./tmdb-5000-movie-dataset/tmdb_5000_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies[['id','title', 'genres', 'vote_average', 'vote_count',\n",
    "                 'popularity', 'keywords', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "movies_df[['genres','keywords']][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**텍스트 문자 1차 가공. 파이썬 딕셔너리 변환 후 리스트 형태로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "movies_df['genres'] = movies_df['genres'].apply(literal_eval)\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genres'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genres'] = movies_df['genres'].apply(lambda x : \n",
    "                                                [ y['name'] for y in x]\n",
    "                                               )\n",
    "movies_df['keywords'] = movies_df['keywords'].apply(lambda x : [ y['name'] for y in x])\n",
    "movies_df[['genres', 'keywords']][:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**장르 콘텐츠 필터링을 이용한 영화 추천. 장르 문자열을 Count 벡터화 후에 코사인 유사도로 각 영화를 비교**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**장르 문자열의 Count기반 피처 벡터화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(('*').join(['test', 'test2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# CountVectorizer를 적용하기 위해 공백문자로 word 단위가 구분되는 문자열로 변환. \n",
    "movies_df['genres_literal'] = movies_df['genres'].apply(lambda x : (' ').join(x))\n",
    "count_vect = CountVectorizer(min_df=0, ngram_range=(1,2))\n",
    "genre_mat = count_vect.fit_transform(movies_df['genres_literal'])\n",
    "print(genre_mat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**장르에 따른 영화별 코사인 유사도 추출**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "genre_sim = cosine_similarity(genre_mat, genre_mat)\n",
    "print(genre_sim.shape)\n",
    "print(genre_sim[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_sim_sorted_ind = genre_sim.argsort()[:, ::-1]\n",
    "print(genre_sim_sorted_ind[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**특정 영화와 장르별 유사도가 높은 영화를 반환하는 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
    "    \n",
    "    # 인자로 입력된 movies_df DataFrame에서 'title' 컬럼이 입력된 title_name 값인 DataFrame추출\n",
    "    title_movie = df[df['title'] == title_name]\n",
    "    \n",
    "    # title_named을 가진 DataFrame의 index 객체를 ndarray로 반환하고 \n",
    "    # sorted_ind 인자로 입력된 genre_sim_sorted_ind 객체에서 유사도 순으로 top_n 개의 index 추출\n",
    "    title_index = title_movie.index.values\n",
    "    similar_indexes = sorted_ind[title_index, :(top_n)]\n",
    "    \n",
    "    # 추출된 top_n index들 출력. top_n index는 2차원 데이터 임. \n",
    "    #dataframe에서 index로 사용하기 위해서 1차원 array로 변경\n",
    "    print(similar_indexes)\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "    \n",
    "    return df.iloc[similar_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
    "similar_movies[['title', 'vote_average']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평점이 높은 영화 정보 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies_df[['title','vote_average','vote_count']].sort_values('vote_average', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평가 횟수에 대한 가중치가 부여된 평점(Weighted Rating) 계산  \n",
    "         가중 평점(Weighted Rating) = (v/(v+m)) * R + (m/(v+m)) * C**\n",
    "         \n",
    "■ v: 개별 영화에 평점을 투표한 횟수\n",
    "■ m: 평점을 부여하기 위한 최소 투표 횟수\n",
    "■ R: 개별 영화에 대한 평균 평점.\n",
    "■ C: 전체 영화에 대한 평균 평점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = movies_df['vote_average'].mean()\n",
    "m = movies_df['vote_count'].quantile(0.6)\n",
    "print('C:',round(C,3), 'm:',round(m,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.6\n",
    "m = movies_df['vote_count'].quantile(percentile)\n",
    "C = movies_df['vote_average'].mean()\n",
    "\n",
    "def weighted_vote_average(record):\n",
    "    v = record['vote_count']\n",
    "    R = record['vote_average']\n",
    "    \n",
    "    return ( (v/(v+m)) * R ) + ( (m/(m+v)) * C )   \n",
    "\n",
    "movies_df['weighted_vote'] = movies_df.apply(weighted_vote_average, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df[['title','vote_average','weighted_vote','vote_count']]\n",
    ".sort_values('weighted_vote', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_sim_movie(df, sorted_ind, title_name, top_n=10):\n",
    "    title_movie = df[df['title'] == title_name]\n",
    "    title_index = title_movie.index.values\n",
    "    \n",
    "    # top_n의 2배에 해당하는 쟝르 유사성이 높은 index 추출 \n",
    "    similar_indexes = sorted_ind[title_index, :(top_n*2)]\n",
    "    similar_indexes = similar_indexes.reshape(-1)\n",
    "# 기준 영화 index는 제외\n",
    "    similar_indexes = similar_indexes[similar_indexes != title_index]\n",
    "    \n",
    "    # top_n의 2배에 해당하는 후보군에서 weighted_vote 높은 순으로 top_n 만큼 추출 \n",
    "    return df.iloc[similar_indexes].sort_values('weighted_vote', ascending=False)[:top_n]\n",
    "\n",
    "similar_movies = find_sim_movie(movies_df, genre_sim_sorted_ind, 'The Godfather',10)\n",
    "similar_movies[['title', 'vote_average', 'weighted_vote']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.2 아이템 기반 인접 이웃 협업 필터링 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**데이터 로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**로우레벨 사용자 평점 데이터를 사용자-아이템 평점 행렬로 변환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "ratings_matrix = ratings.pivot_table('rating', index='userId', columns='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title 컬럼을 얻기 이해 movies 와 조인 수행\n",
    "rating_movies = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "# columns='title' 로 title 컬럼으로 pivot 수행. \n",
    "ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')\n",
    "\n",
    "# NaN 값을 모두 0 으로 변환\n",
    "ratings_matrix = ratings_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영화와 영화들 간 유사도 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_matrix_T = ratings_matrix.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "item_sim = cosine_similarity(ratings_matrix_T, ratings_matrix_T)\n",
    "\n",
    "# cosine_similarity() 로 반환된 넘파이 행렬을 영화명을 매핑하여 DataFrame으로 변환\n",
    "item_sim_df = pd.DataFrame(data=item_sim, index=ratings_matrix.columns,\n",
    "                          columns=ratings_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df[\"Godfather, The (1972)\"].sort_values(ascending=False)[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sim_df[\"Inception (2010)\"].sort_values(ascending=False)[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아이템 기반 인접 이웃 협업 필터링으로 개인화된 영화 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(ratings_arr, item_sim_arr ):\n",
    "    ratings_pred = ratings_arr.dot(item_sim_arr)/ np.array([np.abs(item_sim_arr).sum(axis=1)])\n",
    "    return ratings_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred = predict_rating(ratings_matrix.values , item_sim_df.values)\n",
    "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index= ratings_matrix.index,\n",
    "                                   columns = ratings_matrix.columns)\n",
    "print(ratings_pred_matrix.shape)\n",
    "ratings_pred_matrix.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가중치 평점 부여뒤에 예측 성능 평가 MSE를 구함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 사용자가 평점을 부여한 영화에 대해서만 예측 성능 평가 MSE 를 구함. \n",
    "def get_mse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(pred, actual)\n",
    "\n",
    "print('아이템 기반 모든 인접 이웃 MSE: ', get_mse(ratings_pred, ratings_matrix.values ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**top-n 유사도를 가진 데이터들에 대해서만 예측 평점 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_topsim(ratings_arr, item_sim_arr, n=20):\n",
    "    # 사용자-아이템 평점 행렬 크기만큼 0으로 채운 예측 행렬 초기화\n",
    "    pred = np.zeros(ratings_arr.shape)\n",
    "\n",
    "    # 사용자-아이템 평점 행렬의 열 크기만큼 Loop 수행. \n",
    "    for col in range(ratings_arr.shape[1]):\n",
    "        # 유사도 행렬에서 유사도가 큰 순으로 n개 데이터 행렬의 index 반환\n",
    "        top_n_items = [np.argsort(item_sim_arr[:, col])[:-n-1:-1]]\n",
    "        # 개인화된 예측 평점을 계산\n",
    "        for row in range(ratings_arr.shape[0]):\n",
    "            pred[row, col] = item_sim_arr[col, :][top_n_items].dot(ratings_arr[row, :][top_n_items].T) \n",
    "            pred[row, col] /= np.sum(np.abs(item_sim_arr[col, :][top_n_items]))        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**top-n 유사도 기반의 예측 평점 및 MSE 계산**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred = predict_rating_topsim(ratings_matrix.values , item_sim_df.values, n=20)\n",
    "print('아이템 기반 인접 TOP-20 이웃 MSE: ', get_mse(ratings_pred, ratings_matrix.values ))\n",
    "\n",
    "# 계산된 예측 평점 데이터는 DataFrame으로 재생성\n",
    "ratings_pred_matrix = pd.DataFrame(data=ratings_pred, index= ratings_matrix.index,\n",
    "                                   columns = ratings_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating_id = ratings_matrix.loc[9, :]\n",
    "user_rating_id[ user_rating_id > 0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사용자가 관람하지 않은 영화 중에서 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_movies(ratings_matrix, userId):\n",
    "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
    "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
    "    user_rating = ratings_matrix.loc[userId,:]\n",
    "    \n",
    "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
    "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
    "    \n",
    "    # 모든 영화명을 list 객체로 만듬. \n",
    "    movies_list = ratings_matrix.columns.tolist()\n",
    "    \n",
    "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
    "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
    "    \n",
    "    return unseen_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**아이템 기반 유사도로 평점이 부여된 데이터 세트에서 해당 사용자가 관람하지 않은 영화들의 예측 평점이 가장 높은 영화를 추천**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
    "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
    "    # 가장 예측 평점이 높은 순으로 정렬함. \n",
    "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    return recomm_movies\n",
    "    \n",
    "# 사용자가 관람하지 않는 영화명 추출   \n",
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "# 아이템 기반의 인접 이웃 협업 필터링으로 영화 추천 \n",
    "recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, unseen_list, top_n=10)\n",
    "\n",
    "# 평점 데이타를 DataFrame으로 생성. \n",
    "recomm_movies = pd.DataFrame(data=recomm_movies.values,index=recomm_movies.index,columns=['pred_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.3 잠재 요인 기반 협업 필터링 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강을 이용한 행렬 분해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**원본 행렬 R 및 R을 분해할 P와 Q를 임의의 정규분포를 가진 랜덤값으로 초기화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3 설정. \n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "\n",
    "num_users, num_items = R.shape\n",
    "K=3\n",
    "\n",
    "# P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 random한 값으로 입력합니다. \n",
    "np.random.seed(1)\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    "print(\"P:\",P)\n",
    "print(\"Q:\",Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**비용계산 함수를 생성. 분해된 행렬 P와 Q.T를 내적하여 예측 행렬 생성하고**\n",
    "\n",
    "**실제 행렬에서 널이 아닌 값의 위치에 있는 값만 예측 행렬의 값과 비교하여 RMSE값을 계산하고 반환**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**경사하강법에 기반하여 P와 Q의 원소들을 업데이트 수행**\n",
    "![](./sgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "\n",
    "steps=1000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "\n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행렬 분해 기반의 잠재 요인 협업 필터링 실습\n",
    "\n",
    "**경사하강법 기반의 행렬 분해 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, K, steps=200, learning_rate=0.01, r_lambda = 0.01):\n",
    "    num_users, num_items = R.shape\n",
    "    # P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 랜덤한 값으로 입력합니다. \n",
    "    np.random.seed(1)\n",
    "    P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "    Q = np.random.normal(scale=1./K, size=(num_items, K))\n",
    "\n",
    "    break_count = 0\n",
    "       \n",
    "    # R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트 객체에 저장. \n",
    "    non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "   \n",
    "    # SGD기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "    for step in range(steps):\n",
    "        for i, j, r in non_zeros:\n",
    "            # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "            eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "            # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "            P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "            Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "       \n",
    "        rmse = get_rmse(R, P, Q, non_zeros)\n",
    "        if (step % 10) == 0 :\n",
    "            print(\"### iteration step : \", step,\" rmse : \", rmse)\n",
    "            \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "ratings = ratings[['userId', 'movieId', 'rating']]\n",
    "ratings_matrix = ratings.pivot_table('rating', index='userId', columns='movieId')\n",
    "\n",
    "# title 컬럼을 얻기 이해 movies 와 조인 수행\n",
    "rating_movies = pd.merge(ratings, movies, on='movieId')\n",
    "\n",
    "# columns='title' 로 title 컬럼으로 pivot 수행. \n",
    "ratings_matrix = rating_movies.pivot_table('rating', index='userId', columns='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Q = matrix_factorization(ratings_matrix.values, K=50, steps=200, learning_rate=0.01, r_lambda = 0.01)\n",
    "pred_matrix = np.dot(P, Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred_matrix = pd.DataFrame(data=pred_matrix, index= ratings_matrix.index,\n",
    "                                   columns = ratings_matrix.columns)\n",
    "\n",
    "ratings_pred_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unseen_movies(ratings_matrix, userId):\n",
    "    # userId로 입력받은 사용자의 모든 영화정보 추출하여 Series로 반환함. \n",
    "    # 반환된 user_rating 은 영화명(title)을 index로 가지는 Series 객체임. \n",
    "    user_rating = ratings_matrix.loc[userId,:]\n",
    "    \n",
    "    # user_rating이 0보다 크면 기존에 관람한 영화임. 대상 index를 추출하여 list 객체로 만듬\n",
    "    already_seen = user_rating[ user_rating > 0].index.tolist()\n",
    "    \n",
    "    # 모든 영화명을 list 객체로 만듬. \n",
    "    movies_list = ratings_matrix.columns.tolist()\n",
    "    \n",
    "    # list comprehension으로 already_seen에 해당하는 movie는 movies_list에서 제외함. \n",
    "    unseen_list = [ movie for movie in movies_list if movie not in already_seen]\n",
    "    \n",
    "    return unseen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomm_movie_by_userid(pred_df, userId, unseen_list, top_n=10):\n",
    "    # 예측 평점 DataFrame에서 사용자id index와 unseen_list로 들어온 영화명 컬럼을 추출하여\n",
    "    # 가장 예측 평점이 높은 순으로 정렬함. \n",
    "    recomm_movies = pred_df.loc[userId, unseen_list].sort_values(ascending=False)[:top_n]\n",
    "    return recomm_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 사용자가 관람하지 않는 영화명 추출   \n",
    "unseen_list = get_unseen_movies(ratings_matrix, 9)\n",
    "\n",
    "# 잠재요인 기반 협업 필터링으로 영화 추천 \n",
    "recomm_movies = recomm_movie_by_userid(ratings_pred_matrix, 9, unseen_list, top_n=10)\n",
    "\n",
    "# 평점 데이타를 DataFrame으로 생성. \n",
    "recomm_movies = pd.DataFrame(data=recomm_movies.values,index=recomm_movies.index,columns=['pred_score'])\n",
    "recomm_movies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
